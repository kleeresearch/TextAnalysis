{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleeresearch/TextAnalysis/blob/master/Course/Day5/19_LR_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zlClYEpP_mJ",
        "outputId": "a08a885b-83b2-4217-daa4-52eb7ca533e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7fh_6adWP27A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ixfyt9EXP27C"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/KOSSDA_텍스트마이닝_강의자료/강의자료/Day4/python_code/Korean_movie_reviews_2016_small.txt', encoding='utf-8') as f:\n",
        "    docs = [doc.strip().split('\\t') for doc in f]\n",
        "    docs = [(doc[0], int(doc[1])) for doc in docs if len(doc) == 2]\n",
        "    texts, labels = zip(*docs) # 둘을 분리해서 별도의 list 변수로 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WFbQ0SpqP27D",
        "outputId": "4e30b695-f55e-40ca-bc13-74310b77251c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11994\n",
            "22909\n"
          ]
        }
      ],
      "source": [
        "print(sum(labels))\n",
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lXnRIRxkP27E"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_VkVkgqXP27E"
      },
      "outputs": [],
      "source": [
        "# CounterVectorizer 클래스를 이용한 벡터 표현\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "tf_vectorizer = CountVectorizer()\n",
        "tf_train_features = tf_vectorizer.fit_transform(train_texts)\n",
        "tf_test_features = tf_vectorizer.transform(test_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF IDF 값은 상대적으로 무엇을 더 많이 썼는지에 대한 절대적 빈도 정보\n",
        "\n",
        "TF 정보를 사용하는 것이 더 적합한 젇보\n",
        "\n",
        "각각에 대해서 모형 평가한 다음에 최종적으로 평가데이터에 대해서 모형 성능이 더 좋게 나오는 방법을 사용하면 됨.\n",
        "\n",
        "일반적으로 TF에 대한 방법이 감성분석에서는 더 적합한 방법임.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aEoPDSSeQW_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JDbxJ7NZP27E"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "규제와 관련된 여러가지 파라미터들을 설정할 수 있음. 객체를 만들고 fit function을 이용해서 학습데이터를 학습. feature에 대한 학습, 종속변수에 대한 학습. 평가 데이터에 대해서 평가. predict function을 이용해서 각각의 영화평에 대한 sentiment를 예측. 모형의 성능을 파악하는데 accuracy를 계산. 분류문제의 경우에는 accuracy를 사용하지만 다른 문제도 동시에 리포트 해야 한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "obs3Ym6WQ5QV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tS6Wu6EnP27F"
      },
      "outputs": [],
      "source": [
        "lr_tf_l1 = LogisticRegression(C=0.5, penalty='l1', solver='saga', max_iter=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "unx_yupSP27F",
        "outputId": "e24fb90a-de80-439f-fc1a-c95ceb6e37ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.5, max_iter=10000, penalty='l1', solver='saga')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.5, max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "lr_tf_l1.fit(tf_train_features, train_labels) # 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Mx9AGRL4P27F"
      },
      "outputs": [],
      "source": [
        "pred_labels_tf_l1 = lr_tf_l1.predict(tf_test_features) # 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lN-yx-6QP27F"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model evaluation metrics\n",
        "\n",
        "- accuracy, recall, precision, F1 등 계산을 위해서 confusion matrix 를 사용\n",
        "\n",
        "- 종속변수를 취하는 값이 positive 와 negative로 코딩.\n",
        "\n",
        "컨퓨젼 매트릭스 해석\n",
        "\n",
        "실제값이 행, 예측된 값이 열.\n",
        "초록색으로된 2사분면값 top right 은 실제와 모형을 통해 예측한 값 = 그러한 관측치를 true negative 라고 한다. negative를 negative 라고 관측해서.\n",
        "\n",
        "원래 종속변수의 값이 negative 인데 positive라고 예측해서 false positive.\n",
        "\n",
        "원래 종속변수의 값이 positive인데 negative라고 모형이 예측해서 false negative.\n",
        "\n",
        "원래 종변수값과 모형예측값도 positive를 positive라고 해서 true positive가 됨.\n",
        "\n",
        "매트릭스는 관련된 관측치의 숫자가 된다.\n",
        "\n",
        "모형이 제대로 관측한 수. 모형이 제대로 예측을 못한 관측치의 수. 이러한 행렬을 confusion matrix라고 한다. 이 매트릭스를 이용해서 분류모형의 지표인 accuracy, score값을 계산을 한다.\n",
        "\n",
        "* accuracy는 전체 관측치 중에서 모형이 값ㄷ을 제대로 예측한 비중이다. 전체 관측치의 수는 전체 수를 다 더한 값을 분모 TN+TP+NN=NP, 초록색에 해당하는 제대로 관측한 수가 분자 TN + TP\n",
        "\n",
        "* recall은 클래스별로 그 값이 존재한다. positive class 와 negative class가 있다. 원래의 종속변수 중에서 positive한 것중에서 positive라고 제대로 관측한 것. positive class 재현율은 positive라고 제대로 예측한 관측치의 비중. negative한 관측치 중에서 negative하다고 제대로 관측한 수. positive class에 대한 재현율이기 떄문에 원래의 종속변수의 값이 분모로 가야한다. 원래의 종속변수의 값이 positive한 것들, 분자에는 모형이 positive라고 제대로 예측한 관측치의 수가 분자로 가야 한다. positive class 에 대한 recall 값이다.\n",
        "\n",
        "* 정밀도 precision은 positive class 와 negative class 값이 존재한다. 종속변수의 값을 positive 라고 예측한 값 중에서 positive 라고 관측한 비중이 정밀도가 됨. 우리가 선택한 모형이 종속변수의 값을 positive라고 예측한 관측치 중에서 실제 종속변수의 값이 positive인 값. negative라고 예측한 값 중에서 실제 negative 라고 예측한 값. 분자(TP)/분모(FP+TP)\n",
        "\n",
        "* F1은 precision과 REC의 값.\n",
        "\n",
        "\n",
        "- confusion matrix는 실제 종속변수의 값. true negative, true positive, false positive, false negative가 된다.\n"
      ],
      "metadata": {
        "id": "D2WbOgHARg_1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zHFUft3WP27G",
        "outputId": "6991f425-3cac-4953-fdf0-0cca07414b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 871,  233],\n",
              "       [ 126, 1061]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "confusion_matrix(test_labels, pred_labels_tf_l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QYfNf2vVP27G"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ggqlAxyhP27G",
        "outputId": "1fe85af0-75a7-4e8b-ab67-e95a9f5806b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.79      0.83      1104\n",
            "           1       0.82      0.89      0.86      1187\n",
            "\n",
            "    accuracy                           0.84      2291\n",
            "   macro avg       0.85      0.84      0.84      2291\n",
            "weighted avg       0.85      0.84      0.84      2291\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_labels, pred_labels_tf_l1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3UBRgdTGP27G",
        "outputId": "551cdffa-877b-4ab2-bdcc-203809f7b1e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.30101145 0.69898855]]\n",
            "[1]\n"
          ]
        }
      ],
      "source": [
        "# 하나의 영화평 예측하기\n",
        "print(lr_tf_l1.predict_proba(tf_test_features[0]))\n",
        "print(lr_tf_l1.predict(tf_test_features[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "K8zKM28OP27H"
      },
      "outputs": [],
      "source": [
        "# 단어 사전 만들기\n",
        "words_dict = {}\n",
        "for word, index in tf_vectorizer.vocabulary_.items():\n",
        "    words_dict[index]=word"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "값이 큰 것을 기준으로 상위 30개, 부정을 기준으로 상위 30개 정리.\n",
        "\n",
        "문서의 종속변수의 값이 1이 되는데 있어서 중요한 역할을 하는 것들. 소가로 안의 숫자들은 파라미터의 값을 의미. 파라미터 값이 클수록 긍정.\n",
        "\n",
        "로지스틱 분석으로 감성분석뿐 아니라 어떠한 단어들이 중요한 역할을 하는지 순위 파악도 가능함.\n",
        "\n",
        "\n",
        "만약 다른 분류 작업을 한다고 하면 코로나 19에 대해 정치 성향에 따라 분석한다고 하면...\n",
        "계수값을 이용해서 종속병수의 값이 1(보수), 진보에서 많이 사용하는 단어들 찾을 수 있음.\n",
        "\n",
        "https://www.dbpia.co.kr/pdf/pdfView.do?nodeId=NODE11057266&googleIPSandBox=false&mark=0&ipRange=false&b2cLoginYN=false&isPDFSizeAllowed=true&accessgl=Y&language=ko_KR&hasTopBanner=true\n",
        "\n",
        "\n",
        "시대별 차이도 분석 가능.\n",
        "\n"
      ],
      "metadata": {
        "id": "DmiiknH0V8DP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Wxb3gjCiP27H",
        "outputId": "c9d9433e-e925-4786-a90d-fc68561ec510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "긍정 단어 상위 30 개\n",
            "꿀잼 (3.447)\n",
            "감탄 (2.836)\n",
            "재밌게 (2.829)\n",
            "재밌고 (2.561)\n",
            "재미있게 (2.560)\n",
            "존잼 (2.487)\n",
            "재밌었 (2.404)\n",
            "개꿀잼 (2.367)\n",
            "여운 (2.349)\n",
            "지루하지 (2.314)\n",
            "재밌어 (2.230)\n",
            "감사합 (2.202)\n",
            "재미있었 (2.163)\n",
            "빠르 (2.158)\n",
            "흥미진진 (2.062)\n",
            "강추 (2.055)\n",
            "최고 (1.950)\n",
            "사랑해 (1.947)\n",
            "재미있어 (1.900)\n",
            "재밋어 (1.864)\n",
            "즐겁 (1.841)\n",
            "유쾌 (1.841)\n",
            "아름다운 (1.826)\n",
            "재미있네 (1.818)\n",
            "심장 (1.800)\n",
            "낮아 (1.788)\n",
            "감명 (1.755)\n",
            "재미있고 (1.749)\n",
            "재미있 (1.746)\n",
            "재밌는 (1.704)\n",
            "\n",
            "부정 단어 상위 30 개\n",
            "갑자기 (-1.960)\n",
            "지루해서 (-1.978)\n",
            "댓글알바 (-1.991)\n",
            "알바 (-2.028)\n",
            "그닥 (-2.065)\n",
            "지루하다 (-2.072)\n",
            "별로 (-2.098)\n",
            "왜곡 (-2.142)\n",
            "졸았 (-2.143)\n",
            "지루하고 (-2.147)\n",
            "전형 (-2.161)\n",
            "허무 (-2.184)\n",
            "억지 (-2.200)\n",
            "아까 (-2.234)\n",
            "신파극 (-2.257)\n",
            "짜증 (-2.308)\n",
            "아까운 (-2.352)\n",
            "재미없 (-2.366)\n",
            "엉망 (-2.405)\n",
            "망작 (-2.499)\n",
            "지루했 (-2.501)\n",
            "팔이 (-2.522)\n",
            "역사왜곡 (-2.674)\n",
            "거르 (-2.675)\n",
            "쓰레기 (-2.737)\n",
            "아까웠 (-2.802)\n",
            "이하 (-3.005)\n",
            "차라리 (-3.336)\n",
            "노잼 (-3.620)\n",
            "최악 (-4.687)\n"
          ]
        }
      ],
      "source": [
        "# Get coefficients of the model\n",
        "coefficients = lr_tf_l1.coef_.tolist()\n",
        "\n",
        "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
        "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
        "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
        "\n",
        "\n",
        "K=30\n",
        "# print top K positive words\n",
        "print(\"긍정 단어 상위 {} 개\".format(str(K)))\n",
        "for word_id, coef in sorted_coefficients[:K]:\n",
        "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))\n",
        "# print top K negative words\n",
        "print(\"\\n부정 단어 상위 {} 개\".format(str(K)))\n",
        "for word_id, coef in sorted_coefficients[-K:]:\n",
        "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-S6aJa6qP27H"
      },
      "outputs": [],
      "source": [
        "lr_tf_l2 = LogisticRegression(C=0.5, penalty='l2', solver='saga', max_iter=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "od3hpSEDP27H",
        "outputId": "cf1c4b7e-f65f-4cf4-f043-60d52409cf96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.5, max_iter=10000, solver='saga')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, max_iter=10000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.5, max_iter=10000, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "lr_tf_l2.fit(tf_train_features, train_labels) # 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yWrRhSIsP27H"
      },
      "outputs": [],
      "source": [
        "pred_labels_tf_l2 = lr_tf_l2.predict(tf_test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "M__E-xTLP27H",
        "outputId": "d19c31ec-4994-4682-a886-dd67b4976192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.83      0.85      1104\n",
            "           1       0.85      0.88      0.86      1187\n",
            "\n",
            "    accuracy                           0.86      2291\n",
            "   macro avg       0.86      0.86      0.86      2291\n",
            "weighted avg       0.86      0.86      0.86      2291\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_labels, pred_labels_tf_l2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "macro 평균\n",
        "\n",
        "weighted 평균(가중평균): 젼채 관측치 중에서 평균을 따로 구한 것."
      ],
      "metadata": {
        "id": "VHWqWS68UlN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "predict 기능을 사용하면 0과 1 중에서 예측 가능. 종속변수가 0을 취할 확률, 1을 취할 확률에 대해서 정보를 확인하기 위해 predict_probability 약자인 proba 라는 function을 사용하면 됨. 0.3은 종속변수가 0일 확률,\n",
        "\n",
        "뭐가 더 성능이 좋은지 판단하는 기준은 선행연구를 기준으로 판단 가능"
      ],
      "metadata": {
        "id": "cfmA3mwJVbsa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Pr1Rk4ODP27I",
        "outputId": "011a6e96-afa5-4102-8b5c-8fc5cf9d460b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "긍정 단어 상위 30 개\n",
            "재밌게 (2.619)\n",
            "꿀잼 (2.497)\n",
            "재미있게 (2.241)\n",
            "재밌었 (2.197)\n",
            "재밌어 (2.055)\n",
            "여운 (1.967)\n",
            "재미있었 (1.916)\n",
            "최고 (1.906)\n",
            "재밌고 (1.835)\n",
            "강추 (1.782)\n",
            "감사합 (1.721)\n",
            "지루하지 (1.704)\n",
            "감탄 (1.674)\n",
            "재미있어 (1.655)\n",
            "존잼 (1.585)\n",
            "아름다운 (1.576)\n",
            "재밌는 (1.564)\n",
            "개꿀잼 (1.529)\n",
            "재미있 (1.522)\n",
            "가는 (1.511)\n",
            "흥미진진 (1.509)\n",
            "재밋어 (1.501)\n",
            "재밌 (1.476)\n",
            "가슴 (1.466)\n",
            "지루할 (1.409)\n",
            "재미있네 (1.403)\n",
            "즐겁 (1.375)\n",
            "대박 (1.370)\n",
            "유쾌 (1.357)\n",
            "심장 (1.331)\n",
            "\n",
            "부정 단어 상위 30 개\n",
            "비추 (-1.439)\n",
            "지루하다 (-1.521)\n",
            "지루해서 (-1.541)\n",
            "아깝 (-1.583)\n",
            "지루하고 (-1.617)\n",
            "유치 (-1.618)\n",
            "그닥 (-1.641)\n",
            "엉망 (-1.645)\n",
            "졸았 (-1.654)\n",
            "자고 (-1.663)\n",
            "실망 (-1.690)\n",
            "허무 (-1.705)\n",
            "아까웠 (-1.719)\n",
            "거르 (-1.723)\n",
            "아까 (-1.744)\n",
            "팔이 (-1.770)\n",
            "망작 (-1.785)\n",
            "역사왜곡 (-1.817)\n",
            "알바 (-1.833)\n",
            "짜증 (-1.884)\n",
            "아까운 (-1.909)\n",
            "별로 (-2.026)\n",
            "지루했 (-2.028)\n",
            "억지 (-2.028)\n",
            "이하 (-2.050)\n",
            "재미없 (-2.271)\n",
            "차라리 (-2.290)\n",
            "쓰레기 (-2.395)\n",
            "노잼 (-3.173)\n",
            "최악 (-3.653)\n"
          ]
        }
      ],
      "source": [
        "# Get coefficients of the model\n",
        "coefficients = lr_tf_l2.coef_.tolist()\n",
        "\n",
        "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
        "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
        "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
        "\n",
        "\n",
        "K=30\n",
        "# print top K positive words\n",
        "print(\"긍정 단어 상위 {} 개\".format(str(K)))\n",
        "for word_id, coef in sorted_coefficients[:K]:\n",
        "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))\n",
        "# print top K negative words\n",
        "print(\"\\n부정 단어 상위 {} 개\".format(str(K)))\n",
        "for word_id, coef in sorted_coefficients[-K:]:\n",
        "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀분석으로 학습을 하게 되면 파라미터로 최적값을 찾게 됨. 고유한 파라미터값을 가진다. 파라미터의 값이 bi가 음수이면 해당 단어와 종속변수의 값이 음수면 부정의 관계, 양수면 긍정의 관계가 있다. 파라미터의 값을 확인하게 되면 어떠한 단어가 부정이고 긍정인지 파악할 수 있을 뿐만 아니라 상대적으로 더 많은 부정적인 역할을 하는지 파악할 수 있음."
      ],
      "metadata": {
        "id": "f-fMyI1EVdDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "네트워크 분석을 하면 특정한 형용사/부사 등을 파악할 수 있어 유용하게 사용 가능.\n"
      ],
      "metadata": {
        "id": "f_OH9ONZXQVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GvTulfpBP27I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}